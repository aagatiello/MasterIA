{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Universidad Internacional de La Rioja (UNIR) - Máster Universitario en Inteligencia Artificial - Procesamiento del Lenguaje Natural** "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"font-size: 20pt; font-weight: bold; color: #0098cd;\">Trabajo: Named-Entity Recognition</span>\n",
    "\n",
    "**Objetivos** \n",
    "\n",
    "Con esta actividad se tratará de que el alumno se familiarice con el manejo de la librería spacy, así como con los conceptos básicos de manejo de las técnicas NER\n",
    "\n",
    "**Descripción**\n",
    "\n",
    "En esta actividad debes procesar de forma automática un texto en lenguaje natural para detectar características básicas en el mismo, y para identificar y etiquetar las ocurrencias de conceptos como localización, moneda, empresas, etc.\n",
    "\n",
    "En la primera parte del ejercicio se proporciona un código fuente a través del cual se lee un archivo de texto y se realiza un preprocesado del mismo. En esta parte el alumno tan sólo debe ejecutar y entender el código proporcionado.\n",
    "\n",
    "En la segunda parte del ejercicio se plantean una serie de preguntas que deben ser respondidas por el alumno. Cada pregunta deberá responderse con un fragmento de código fuente que esté acompañado de la explicación correspondiente. Para elaborar el código solicitado, el alumno deberá visitar la documentación de la librería spacy, cuyos enlaces se proporcionarán donde corresponda."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parte 1: carga y preprocesamiento del texto a analizar"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Observa las diferentes librerías que se están importando."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-27T21:41:54.081311Z",
     "start_time": "2023-04-27T21:41:53.550437Z"
    }
   },
   "outputs": [],
   "source": [
    "import pathlib\n",
    "import spacy\n",
    "from spacy import displacy\n",
    "import en_core_web_sm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El siguiente código simplemente carga y preprocesa el texto. Para ello, lo primero que hace es cargar un modelo de lenguaje previamente entrenado. En este caso, se utiliza <i>en_core_web_sm</i>: \n",
    "\n",
    "https://spacy.io/models/en#en_core_web_sm\n",
    "\n",
    "Al cargar el modelo de lenguaje se genera un <i>Pipeline</i>, que nos permite realizar las diferentes tareas. En este caso, vamos a utilizar el pipeline para hacer un preprocesamiento básico, que consiste en tokenizar el texto.\n",
    "\n",
    "Al final del código proporcionado <i>doc</i> representa una versión tokenizada del texto leído."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-27T21:41:54.676992Z",
     "start_time": "2023-04-27T21:41:54.082320Z"
    }
   },
   "outputs": [],
   "source": [
    "nlp = en_core_web_sm.load()\n",
    "file_name = \"barack-obama-speech.txt\"\n",
    "doc = nlp(pathlib.Path(file_name).read_text(encoding=\"utf-8\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Playground\n",
    "\n",
    "La variable <i>doc</i> es un objeto de la clase <i>Doc</i> (https://spacy.io/api/doc)\n",
    "\n",
    "Visita la documentación de dicha clase y experimenta probando las diferentes funciones y atributos "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-27T21:41:54.684238Z",
     "start_time": "2023-04-27T21:41:54.677999Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "“Hello, Chicago.\n",
       "If there is anyone out there who still doubts that America is a place where all things are possible, who still wonders if the dream of our founders is alive in our time, who still questions the power of our democracy, tonight is your answer.\n",
       "It’s the answer told by lines that stretched around schools and churches in numbers this nation has never seen, by people who waited three hours and four hours, many for the first time in their lives, because they believed that this time must be different, that their voices could be that difference.\n",
       "It’s the answer spoken by young and old, rich and poor, Democrat and Republican, black, white, Hispanic, Asian, Native American, gay, straight, disabled and not disabled. Americans who sent a message to the world that we have never been just a collection of individuals or a collection of red states and blue states.\n",
       "We are, and always will be, the United States of America.\n",
       "It’s the answer that led those who’ve been told for so long by so many to be cynical and fearful and doubtful about what we can achieve to put their hands on the arc of history and bend it once more toward the hope of a better day.\n",
       "It’s been a long time coming, but tonight, because of what we did on this date in this election at this defining moment change has come to America.\n",
       "[read more]\n",
       "\n",
       "We didn’t start with much money or many endorsements. Our campaign was not hatched in the halls of Washington. It began in the backyards of Des Moines and the living rooms of Concord and the front porches of Charleston. It was built by working men and women who dug into what little savings they had to give $5 and $10 and $20 to the cause.\n",
       "It grew strength from the young people who rejected the myth of their generation’s apathy who left their homes and their families for jobs that offered little pay and less sleep.\n",
       "It drew strength from the not-so-young people who braved the bitter cold and scorching heat to knock on doors of perfect strangers, and from the millions of Americans who volunteered and organized and proved that more than two centuries later a government of the people, by the people, and for the people has not perished from the Earth.\n",
       "This is your victory.\n",
       "And I know you didn’t do this just to win an election. And I know you didn’t do it for me.\n",
       "You did it because you understand the enormity of the task that lies ahead. For even as we celebrate tonight, we know the challenges that tomorrow will bring are the greatest of our lifetime — two wars, a planet in peril, the worst financial crisis in a century.\n",
       "Even as we stand here tonight, we know there are brave Americans waking up in the deserts of Iraq and the mountains of Afghanistan to risk their lives for us.\n",
       "There are mothers and fathers who will lie awake after the children fall asleep and wonder how they’ll make the mortgage or pay their doctors’ bills or save enough for their child’s college education.\n",
       "There’s new energy to harness, new jobs to be created, new schools to build, and threats to meet, alliances to repair.\n",
       "The road ahead will be long. Our climb will be steep. We may not get there in one year or even in one term. But, America, I have never been more hopeful than I am tonight that we will get there.\n",
       "I promise you, we as a people will get there.\n",
       "There will be setbacks and false starts. There are many who won’t agree with every decision or policy I make as president. And we know the government can’t solve every problem.\n",
       "But I will always be honest with you about the challenges we face. I will listen to you, especially when we disagree. And, above all, I will ask you to join in the work of remaking this nation, the only way it’s been done in America for 221 years — block by block, brick by brick, calloused hand by calloused hand.\n",
       "What began 21 months ago in the depths of winter cannot end on this autumn night.\n",
       "This victory alone is not the change we seek. It is only the chance for us to make that change. And that cannot happen if we go back to the way things were.\n",
       "It can’t happen without you, without a new spirit of service, a new spirit of sacrifice.\n",
       "So let us summon a new spirit of patriotism, of responsibility, where each of us resolves to pitch in and work harder and look after not only ourselves but each other.\n",
       "Let us remember that, if this financial crisis taught us anything, it’s that we cannot have a thriving Wall Street while Main Street suffers.\n",
       "In this country, we rise or fall as one nation, as one people. Let’s resist the temptation to fall back on the same partisanship and pettiness and immaturity that has poisoned our politics for so long.\n",
       "Let’s remember that it was a man from this state who first carried the banner of the Republican Party to the White House, a party founded on the values of self-reliance and individual liberty and national unity.\n",
       "Those are values that we all share. And while the Democratic Party has won a great victory tonight, we do so with a measure of humility and determination to heal the divides that have held back our progress.\n",
       "As Lincoln said to a nation far more divided than ours, we are not enemies but friends. Though passion may have strained, it must not break our bonds of affection.\n",
       "And to those Americans whose support I have yet to earn, I may not have won your vote tonight, but I hear your voices. I need your help. And I will be your president, too.\n",
       "And to all those watching tonight from beyond our shores, from parliaments and palaces, to those who are huddled around radios in the forgotten corners of the world, our stories are singular, but our destiny is shared, and a new dawn of American leadership is at hand.\n",
       "To those — to those who would tear the world down: We will defeat you. To those who seek peace and security: We support you. And to all those who have wondered if America’s beacon still burns as bright: Tonight we proved once more that the true strength of our nation comes not from the might of our arms or the scale of our wealth, but from the enduring power of our ideals: democracy, liberty, opportunity and unyielding hope.\n",
       "That’s the true genius of America: that America can change. Our union can be perfected. What we’ve already achieved gives us hope for what we can and must achieve tomorrow.\n",
       "This election had many firsts and many stories that will be told for generations. But one that’s on my mind tonight’s about a woman who cast her ballot in Atlanta. She’s a lot like the millions of others who stood in line to make their voice heard in this election except for one thing: Ann Nixon Cooper is 106 years old.\n",
       "She was born just a generation past slavery; a time when there were no cars on the road or planes in the sky; when someone like her couldn’t vote for two reasons — because she was a woman and because of the color of her skin.\n",
       "And tonight, I think about all that she’s seen throughout her century in America — the heartache and the hope; the struggle and the progress; the times we were told that we can’t, and the people who pressed on with that American creed: Yes we can.\n",
       "At a time when women’s voices were silenced and their hopes dismissed, she lived to see them stand up and speak out and reach for the ballot. Yes we can.\n",
       "When there was despair in the dust bowl and depression across the land, she saw a nation conquer fear itself with a New Deal, new jobs, a new sense of common purpose. Yes we can.\n",
       "When the bombs fell on our harbor and tyranny threatened the world, she was there to witness a generation rise to greatness and a democracy was saved. Yes we can.\n",
       "She was there for the buses in Montgomery, the hoses in Birmingham, a bridge in Selma, and a preacher from Atlanta who told a people that “We Shall Overcome.” Yes we can.\n",
       "A man touched down on the moon, a wall came down in Berlin, a world was connected by our own science and imagination.\n",
       "And this year, in this election, she touched her finger to a screen, and cast her vote, because after 106 years in America, through the best of times and the darkest of hours, she knows how America can change.\n",
       "Yes we can.\n",
       "America, we have come so far. We have seen so much. But there is so much more to do. So tonight, let us ask ourselves — if our children should live to see the next century; if my daughters should be so lucky to live as long as Ann Nixon Cooper, what change will they see? What progress will we have made?\n",
       "This is our chance to answer that call. This is our moment.\n",
       "This is our time, to put our people back to work and open doors of opportunity for our kids; to restore prosperity and promote the cause of peace; to reclaim the American dream and reaffirm that fundamental truth, that, out of many, we are one; that while we breathe, we hope. And where we are met with cynicism and doubts and those who tell us that we can’t, we will respond with that timeless creed that sums up the spirit of a people: Yes, we can.["
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parte 2: preguntas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para responder a cada una de las preguntas planteadas deberás aportar tanto el código fuente con el cual puedes conseguir la respuesta, como una explicación válida de la respuesta y de la forma de obtenerla."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"font-size: 14pt; font-weight: bold; color: #0098cd;\">Pregunta 1.</span>\n",
    "<span style=\"font-size: 14pt; font-weight: bold; color: #0098cd;\">¿Cuántas palabras tiene el texto?</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-27T21:41:54.690125Z",
     "start_time": "2023-04-27T21:41:54.685247Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "El texto contiene 1893 palabras.\n"
     ]
    }
   ],
   "source": [
    "num_palabras = sum(1 for token in doc if not token.is_space)\n",
    "print(\"El texto contiene\", num_palabras, \"palabras.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-27T21:41:54.693834Z",
     "start_time": "2023-04-27T21:41:54.691136Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "El texto contiene 1646 palabras.\n"
     ]
    }
   ],
   "source": [
    "num_palabras = sum(1 for token in doc if token.is_alpha)\n",
    "print(\"El texto contiene\", num_palabras, \"palabras.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Incluye aquí, debajo de la línea, la explicación de tu respuesta</b>\n",
    "<hr>\n",
    "En la primera celda he creado un contador que suma 1 según las palabras, correspondientes con un token, que se encuentra en el texto excluyendo los espacios gracias a la función <i>is_space</i>. Este atributo devuelve un boleano según si el token consiste en un espacio en blanco.\n",
    "\n",
    "En la segunda celda he sustituido la función de excluir espacios por <i>is_alfa</i>, que solo cuenta aquellos tokens que contienen caracteres alfabéticos. De esta forma creo que el recuento es más aproximado al ser el correcto ya que no solo omite espacios, sino también signos de puntuación (comas, puntos, guiones, etc.) y caracteres numéricos. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"font-size: 14pt; font-weight: bold; color: #0098cd;\">Pregunta 2.</span>\n",
    "<span style=\"font-size: 14pt; font-weight: bold; color: #0098cd;\">¿Cuántas oraciones tiene el texto?</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-27T21:41:54.697511Z",
     "start_time": "2023-04-27T21:41:54.693834Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "El texto contiene 83 oraciones.\n"
     ]
    }
   ],
   "source": [
    "num_oraciones = len(list(doc.sents))\n",
    "print(\"El texto contiene\", num_oraciones, \"oraciones.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Incluye aquí, debajo de la línea, la explicación de tu respuesta</b>\n",
    "<hr>\n",
    "He utilizado el método <i>sents</i> del objeto doc, que permite detectar los límites de las oraciones para poder separarlas. Con la función <i>list()</i> transformo el resultado en una lista y luego cuento sus elementos utilizando <i>len()</i>."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"font-size: 14pt; font-weight: bold; color: #0098cd;\">Pregunta 3.</span>\n",
    "<span style=\"font-size: 14pt; font-weight: bold; color: #0098cd;\">¿Cuál el número de palabras de la oración más grande? ¿Cual es dicha oración?</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-27T21:41:54.701771Z",
     "start_time": "2023-04-27T21:41:54.698522Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "La oración más larga contiene 67 palabras.\n",
      "Esta oración es: It drew strength from the not-so-young people who braved the bitter cold and scorching heat to knock on doors of perfect strangers, and from the millions of Americans who volunteered and organized and proved that more than two centuries later a government of the people, by the people, and for the people has not perished from the Earth.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "oracion = max(doc.sents, key=lambda sent: len(sent))\n",
    "num_palabras = len(oracion)\n",
    "print(\"La oración más larga contiene\", num_palabras, \"palabras.\")\n",
    "print(\"Esta oración es:\", oracion.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Incluye aquí, debajo de la línea, la explicación de tu respuesta</b>\n",
    "<hr>\n",
    "Para encontrar la oración más larga he iterado por el conjunto de oraciones del texto con el método que había encontrado en el apartado anterior. Utilizo lambda para poder definir la longitud de caracteres de cada oración a partir del atributo <i>sent</i>. Como todo ello está dentro de la función <i>max()</i>, el resultado será la oración más larga en términos de longitud de caracteres.\n",
    "\n",
    "Una vez identificada la oración, hago una cuenta del número de caracteres con <i>len()</i>."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"font-size: 14pt; font-weight: bold; color: #0098cd;\">Pregunta 4.</span>\n",
    "<span style=\"font-size: 14pt; font-weight: bold; color: #0098cd;\">¿Cómo puedes acceder al lema, lexema y morfemas de cada token?</span>\n",
    "\n",
    "Recomendación: si no lo has hecho ya, visita la documentación de la clase <i>Token</i>: https://spacy.io/api/token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-27T21:41:54.705486Z",
     "start_time": "2023-04-27T21:41:54.702967Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Texto: is\n",
      "Lema: be\n",
      "Lexema: <spacy.lexeme.Lexeme object at 0x000001EE97D2B900>\n",
      "Morfemas: Mood=Ind|Number=Sing|Person=3|Tense=Pres|VerbForm=Fin\n"
     ]
    }
   ],
   "source": [
    "token = doc[8]\n",
    "print(\"Texto:\", token.text)\n",
    "print(\"Lema:\", token.lemma_)\n",
    "print(\"Lexema:\", token.lex)\n",
    "print(\"Morfemas:\", token.morph)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Incluye aquí, debajo de la línea, la explicación de tu respuesta</b>\n",
    "<hr>\n",
    "He guardado como token el índice de la palabra que quería analizar del objeto doc, que no es más que su posición en el texto. He buscado un verbo así podía ver la diferencia entre el contenido del texto (.text) del token y su lema. \n",
    "\n",
    "Para acceder al lema llamamos al atributo <i>lemma_</i> que devuelve la forma inicial del token en forma de string. Tambien existe <i>lemma</i> pero devuelve su valor numérico. El lexema se obtiene a partir de <i>lex</i> , que es de tipo Lexeme y al no ser parte del POS tagging, dependencias o lemas, no devuelve un resultado textual sino el código del tipo de palabra al que pertenece. Para el morfema se utiliza <i>morph</i> para obtener el análisis morfolófico, que proviene del tipo MorphAnalysis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"font-size: 14pt; font-weight: bold; color: #0098cd;\">Pregunta 5.</span>\n",
    "<span style=\"font-size: 14pt; font-weight: bold; color: #0098cd;\">¿Cómo puedes identificar/eliminar las stop words?</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-27T21:41:54.710120Z",
     "start_time": "2023-04-27T21:41:54.706504Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['If', 'there', 'is', 'anyone', 'out', 'there', 'who', 'still', 'that', 'is', 'a', 'where', 'all', 'are', 'who', 'still', 'if', 'the', 'of', 'our', 'is', 'in', 'our', 'who', 'still', 'the', 'of', 'our', 'is', 'your', 'It', '’s', 'the', 'by', 'that', 'around', 'and', 'in', 'this', 'has', 'never', 'by', 'who', 'three', 'and', 'four', 'many', 'for', 'the', 'first', 'in', 'their', 'because', 'they', 'that', 'this', 'must', 'be', 'that', 'their', 'could', 'be', 'that', 'It', '’s', 'the', 'by', 'and', 'and', 'and', 'and', 'not', 'who', 'a', 'to', 'the', 'that', 'we', 'have', 'never', 'been', 'just', 'a', 'of', 'or', 'a', 'of', 'and', 'We', 'are', 'and', 'always', 'will', 'be', 'the', 'of', 'It', '’s', 'the', 'that', 'those', 'who', '’ve', 'been', 'for', 'so', 'by', 'so', 'many', 'to', 'be', 'and', 'and', 'about', 'what', 'we', 'can', 'to', 'put', 'their', 'on', 'the', 'of', 'and', 'it', 'once', 'more', 'toward', 'the', 'of', 'a', 'It', '’s', 'been', 'a', 'but', 'because', 'of', 'what', 'we', 'did', 'on', 'this', 'in', 'this', 'at', 'this', 'has', 'to', 'more', 'We', 'did', 'n’t', 'with', 'much', 'or', 'many', 'Our', 'was', 'not', 'in', 'the', 'of', 'It', 'in', 'the', 'of', 'and', 'the', 'of', 'and', 'the', 'front', 'of', 'It', 'was', 'by', 'and', 'who', 'into', 'what', 'they', 'had', 'to', 'give', 'and', 'and', 'to', 'the', 'It', 'from', 'the', 'who', 'the', 'of', 'their', '’s', 'who', 'their', 'and', 'their', 'for', 'that', 'and', 'less', 'It', 'from', 'the', 'not', 'so', 'who', 'the', 'and', 'to', 'on', 'of', 'and', 'from', 'the', 'of', 'who', 'and', 'and', 'that', 'more', 'than', 'two', 'a', 'of', 'the', 'by', 'the', 'and', 'for', 'the', 'has', 'not', 'from', 'the', 'This', 'is', 'your', 'And', 'I', 'you', 'did', 'n’t', 'do', 'this', 'just', 'to', 'an', 'And', 'I', 'you', 'did', 'n’t', 'do', 'it', 'for', 'me', 'You', 'did', 'it', 'because', 'you', 'the', 'of', 'the', 'that', 'For', 'even', 'as', 'we', 'we', 'the', 'that', 'will', 'are', 'the', 'of', 'our', 'two', 'a', 'in', 'the', 'in', 'a', 'Even', 'as', 'we', 'here', 'we', 'there', 'are', 'up', 'in', 'the', 'of', 'and', 'the', 'of', 'to', 'their', 'for', 'us', 'There', 'are', 'and', 'who', 'will', 'after', 'the', 'and', 'how', 'they', '’ll', 'make', 'the', 'or', 'their', 'or', 'enough', 'for', 'their', '’s', 'There', '’s', 'to', 'to', 'be', 'to', 'and', 'to', 'to', 'The', 'will', 'be', 'Our', 'will', 'be', 'We', 'may', 'not', 'get', 'there', 'in', 'one', 'or', 'even', 'in', 'one', 'But', 'I', 'have', 'never', 'been', 'more', 'than', 'I', 'am', 'that', 'we', 'will', 'get', 'there', 'I', 'you', 'we', 'as', 'a', 'will', 'get', 'there', 'There', 'will', 'be', 'and', 'There', 'are', 'many', 'who', 'n’t', 'with', 'every', 'or', 'I', 'make', 'as', 'And', 'we', 'the', 'ca', 'n’t', 'every', 'But', 'I', 'will', 'always', 'be', 'with', 'you', 'about', 'the', 'we', 'I', 'will', 'to', 'you', 'when', 'we', 'And', 'above', 'all', 'I', 'will', 'you', 'to', 'in', 'the', 'of', 'this', 'the', 'only', 'it', '’s', 'been', 'done', 'in', 'for', 'by', 'by', 'by', 'What', 'in', 'the', 'of', 'can', 'not', 'on', 'this', 'This', 'alone', 'is', 'not', 'the', 'we', 'It', 'is', 'only', 'the', 'for', 'us', 'to', 'make', 'that', 'And', 'that', 'can', 'not', 'if', 'we', 'go', 'back', 'to', 'the', 'were', 'It', 'ca', 'n’t', 'without', 'you', 'without', 'a', 'of', 'a', 'of', 'So', 'us', 'a', 'of', 'of', 'where', 'each', 'of', 'us', 'to', 'in', 'and', 'and', 'after', 'not', 'only', 'ourselves', 'but', 'each', 'other', 'us', 'that', 'if', 'this', 'us', 'anything', 'it', '’s', 'that', 'we', 'can', 'not', 'have', 'a', 'while', 'In', 'this', 'we', 'or', 'as', 'one', 'as', 'one', '’s', 'the', 'to', 'back', 'on', 'the', 'same', 'and', 'and', 'that', 'has', 'our', 'for', 'so', '’s', 'that', 'it', 'was', 'a', 'from', 'this', 'who', 'first', 'the', 'of', 'the', 'to', 'the', 'a', 'on', 'the', 'of', 'and', 'and', 'Those', 'are', 'that', 'we', 'all', 'And', 'while', 'the', 'has', 'a', 'we', 'do', 'so', 'with', 'a', 'of', 'and', 'to', 'the', 'that', 'have', 'back', 'our', 'As', 'to', 'a', 'more', 'than', 'ours', 'we', 'are', 'not', 'but', 'Though', 'may', 'have', 'it', 'must', 'not', 'our', 'of', 'And', 'to', 'those', 'whose', 'I', 'have', 'yet', 'to', 'I', 'may', 'not', 'have', 'your', 'but', 'I', 'your', 'I', 'your', 'And', 'I', 'will', 'be', 'your', 'too', 'And', 'to', 'all', 'those', 'from', 'beyond', 'our', 'from', 'and', 'to', 'those', 'who', 'are', 'around', 'in', 'the', 'of', 'the', 'our', 'are', 'but', 'our', 'is', 'and', 'a', 'of', 'is', 'at', 'To', 'those', 'to', 'those', 'who', 'would', 'the', 'down', 'We', 'will', 'you', 'To', 'those', 'who', 'and', 'We', 'you', 'And', 'to', 'all', 'those', 'who', 'have', 'if', '’s', 'still', 'as', 'we', 'once', 'more', 'that', 'the', 'of', 'our', 'not', 'from', 'the', 'might', 'of', 'our', 'or', 'the', 'of', 'our', 'but', 'from', 'the', 'of', 'our', 'and', 'That', '’s', 'the', 'of', 'that', 'can', 'Our', 'can', 'be', 'What', 'we', '’ve', 'already', 'us', 'for', 'what', 'we', 'can', 'and', 'must', 'This', 'had', 'many', 'and', 'many', 'that', 'will', 'be', 'for', 'But', 'one', 'that', '’s', 'on', 'my', '’s', 'about', 'a', 'who', 'her', 'in', 'She', '’s', 'a', 'the', 'of', 'others', 'who', 'in', 'to', 'make', 'their', 'in', 'this', 'except', 'for', 'one', 'is', 'She', 'was', 'just', 'a', 'a', 'when', 'there', 'were', 'no', 'on', 'the', 'or', 'in', 'the', 'when', 'someone', 'her', 'could', 'n’t', 'for', 'two', 'because', 'she', 'was', 'a', 'and', 'because', 'of', 'the', 'of', 'her', 'And', 'I', 'about', 'all', 'that', 'she', '’s', 'throughout', 'her', 'in', 'the', 'and', 'the', 'the', 'and', 'the', 'the', 'we', 'were', 'that', 'we', 'ca', 'n’t', 'and', 'the', 'who', 'on', 'with', 'that', 'we', 'can', 'At', 'a', 'when', '’s', 'were', 'and', 'their', 'she', 'to', 'see', 'them', 'up', 'and', 'out', 'and', 'for', 'the', 'we', 'can', 'When', 'there', 'was', 'in', 'the', 'and', 'across', 'the', 'she', 'a', 'itself', 'with', 'a', 'a', 'of', 'we', 'can', 'When', 'the', 'on', 'our', 'and', 'the', 'she', 'was', 'there', 'to', 'a', 'to', 'and', 'a', 'was', 'we', 'can', 'She', 'was', 'there', 'for', 'the', 'in', 'the', 'in', 'a', 'in', 'and', 'a', 'from', 'who', 'a', 'that', 'We', 'we', 'can', 'A', 'down', 'on', 'the', 'a', 'down', 'in', 'a', 'was', 'by', 'our', 'own', 'and', 'And', 'this', 'in', 'this', 'she', 'her', 'to', 'a', 'and', 'her', 'because', 'after', 'in', 'through', 'the', 'of', 'and', 'the', 'of', 'she', 'how', 'can', 'we', 'can', 'we', 'have', 'so', 'We', 'have', 'so', 'much', 'But', 'there', 'is', 'so', 'much', 'more', 'to', 'do', 'So', 'us', 'ourselves', 'if', 'our', 'should', 'to', 'see', 'the', 'next', 'if', 'my', 'should', 'be', 'so', 'to', 'as', 'as', 'what', 'will', 'they', 'see', 'What', 'will', 'we', 'have', 'made', 'This', 'is', 'our', 'to', 'that', 'call', 'This', 'is', 'our', 'This', 'is', 'our', 'to', 'put', 'our', 'back', 'to', 'and', 'of', 'for', 'our', 'to', 'and', 'the', 'of', 'to', 'the', 'and', 'that', 'that', 'out', 'of', 'many', 'we', 'are', 'one', 'that', 'while', 'we', 'we', 'And', 'where', 'we', 'are', 'with', 'and', 'and', 'those', 'who', 'us', 'that', 'we', 'ca', 'n’t', 'we', 'will', 'with', 'that', 'that', 'up', 'the', 'of', 'a', 'we', 'can']\n"
     ]
    }
   ],
   "source": [
    "# Identificar stop words\n",
    "stopwords = []\n",
    "for token in doc:\n",
    "    if token.is_stop:\n",
    "        stopwords.append(token.text)\n",
    "print(stopwords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-27T21:41:54.714531Z",
     "start_time": "2023-04-27T21:41:54.711355Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[“, Hello, ,, Chicago, ., \n",
      ", doubts, America, place, things, possible, ,, wonders, dream, founders, alive, time, ,, questions, power, democracy, ,, tonight, answer, ., \n",
      ", answer, told, lines, stretched, schools, churches, numbers, nation, seen, ,, people, waited, hours, hours, ,, time, lives, ,, believed, time, different, ,, voices, difference, ., \n",
      ", answer, spoken, young, old, ,, rich, poor, ,, Democrat, Republican, ,, black, ,, white, ,, Hispanic, ,, Asian, ,, Native, American, ,, gay, ,, straight, ,, disabled, disabled, ., Americans, sent, message, world, collection, individuals, collection, red, states, blue, states, ., \n",
      ", ,, ,, United, States, America, ., \n",
      ", answer, led, told, long, cynical, fearful, doubtful, achieve, hands, arc, history, bend, hope, better, day, ., \n",
      ", long, time, coming, ,, tonight, ,, date, election, defining, moment, change, come, America, ., \n",
      ", [, read, ], \n",
      "\n",
      ", start, money, endorsements, ., campaign, hatched, halls, Washington, ., began, backyards, Des, Moines, living, rooms, Concord, porches, Charleston, ., built, working, men, women, dug, little, savings, $, 5, $, 10, $, 20, cause, ., \n",
      ", grew, strength, young, people, rejected, myth, generation, apathy, left, homes, families, jobs, offered, little, pay, sleep, ., \n",
      ", drew, strength, -, -, young, people, braved, bitter, cold, scorching, heat, knock, doors, perfect, strangers, ,, millions, Americans, volunteered, organized, proved, centuries, later, government, people, ,, people, ,, people, perished, Earth, ., \n",
      ", victory, ., \n",
      ", know, win, election, ., know, ., \n",
      ", understand, enormity, task, lies, ahead, ., celebrate, tonight, ,, know, challenges, tomorrow, bring, greatest, lifetime, —, wars, ,, planet, peril, ,, worst, financial, crisis, century, ., \n",
      ", stand, tonight, ,, know, brave, Americans, waking, deserts, Iraq, mountains, Afghanistan, risk, lives, ., \n",
      ", mothers, fathers, lie, awake, children, fall, asleep, wonder, mortgage, pay, doctors, ’, bills, save, child, college, education, ., \n",
      ", new, energy, harness, ,, new, jobs, created, ,, new, schools, build, ,, threats, meet, ,, alliances, repair, ., \n",
      ", road, ahead, long, ., climb, steep, ., year, term, ., ,, America, ,, hopeful, tonight, ., \n",
      ", promise, ,, people, ., \n",
      ", setbacks, false, starts, ., wo, agree, decision, policy, president, ., know, government, solve, problem, ., \n",
      ", honest, challenges, face, ., listen, ,, especially, disagree, ., ,, ,, ask, join, work, remaking, nation, ,, way, America, 221, years, —, block, block, ,, brick, brick, ,, calloused, hand, calloused, hand, ., \n",
      ", began, 21, months, ago, depths, winter, end, autumn, night, ., \n",
      ", victory, change, seek, ., chance, change, ., happen, way, things, ., \n",
      ", happen, ,, new, spirit, service, ,, new, spirit, sacrifice, ., \n",
      ", let, summon, new, spirit, patriotism, ,, responsibility, ,, resolves, pitch, work, harder, look, ., \n",
      ", Let, remember, ,, financial, crisis, taught, ,, thriving, Wall, Street, Main, Street, suffers, ., \n",
      ", country, ,, rise, fall, nation, ,, people, ., Let, resist, temptation, fall, partisanship, pettiness, immaturity, poisoned, politics, long, ., \n",
      ", Let, remember, man, state, carried, banner, Republican, Party, White, House, ,, party, founded, values, self, -, reliance, individual, liberty, national, unity, ., \n",
      ", values, share, ., Democratic, Party, won, great, victory, tonight, ,, measure, humility, determination, heal, divides, held, progress, ., \n",
      ", Lincoln, said, nation, far, divided, ,, enemies, friends, ., passion, strained, ,, break, bonds, affection, ., \n",
      ", Americans, support, earn, ,, won, vote, tonight, ,, hear, voices, ., need, help, ., president, ,, ., \n",
      ", watching, tonight, shores, ,, parliaments, palaces, ,, huddled, radios, forgotten, corners, world, ,, stories, singular, ,, destiny, shared, ,, new, dawn, American, leadership, hand, ., \n",
      ", —, tear, world, :, defeat, ., seek, peace, security, :, support, ., wondered, America, beacon, burns, bright, :, Tonight, proved, true, strength, nation, comes, arms, scale, wealth, ,, enduring, power, ideals, :, democracy, ,, liberty, ,, opportunity, unyielding, hope, ., \n",
      ", true, genius, America, :, America, change, ., union, perfected, ., achieved, gives, hope, achieve, tomorrow, ., \n",
      ", election, firsts, stories, told, generations, ., mind, tonight, woman, cast, ballot, Atlanta, ., lot, like, millions, stood, line, voice, heard, election, thing, :, Ann, Nixon, Cooper, 106, years, old, ., \n",
      ", born, generation, past, slavery, ;, time, cars, road, planes, sky, ;, like, vote, reasons, —, woman, color, skin, ., \n",
      ", tonight, ,, think, seen, century, America, —, heartache, hope, ;, struggle, progress, ;, times, told, ,, people, pressed, American, creed, :, Yes, ., \n",
      ", time, women, voices, silenced, hopes, dismissed, ,, lived, stand, speak, reach, ballot, ., Yes, ., \n",
      ", despair, dust, bowl, depression, land, ,, saw, nation, conquer, fear, New, Deal, ,, new, jobs, ,, new, sense, common, purpose, ., Yes, ., \n",
      ", bombs, fell, harbor, tyranny, threatened, world, ,, witness, generation, rise, greatness, democracy, saved, ., Yes, ., \n",
      ", buses, Montgomery, ,, hoses, Birmingham, ,, bridge, Selma, ,, preacher, Atlanta, told, people, “, Shall, Overcome, ., ”, Yes, ., \n",
      ", man, touched, moon, ,, wall, came, Berlin, ,, world, connected, science, imagination, ., \n",
      ", year, ,, election, ,, touched, finger, screen, ,, cast, vote, ,, 106, years, America, ,, best, times, darkest, hours, ,, knows, America, change, ., \n",
      ", Yes, ., \n",
      ", America, ,, come, far, ., seen, ., ., tonight, ,, let, ask, —, children, live, century, ;, daughters, lucky, live, long, Ann, Nixon, Cooper, ,, change, ?, progress, ?, \n",
      ", chance, answer, ., moment, ., \n",
      ", time, ,, people, work, open, doors, opportunity, kids, ;, restore, prosperity, promote, cause, peace, ;, reclaim, American, dream, reaffirm, fundamental, truth, ,, ,, ,, ;, breathe, ,, hope, ., met, cynicism, doubts, tell, ,, respond, timeless, creed, sums, spirit, people, :, Yes, ,, ., [, \n",
      "]\n"
     ]
    }
   ],
   "source": [
    "# Eliminar stop words\n",
    "doc_nostpwrd = [token for token in doc if not token.is_stop]\n",
    "print(doc_nostpwrd)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Incluye aquí, debajo de la línea, la explicación de tu respuesta</b>\n",
    "<hr>\n",
    "Al igual que existe <i>is_space</i>, los tokens tienen el atributo <i>is_stop</i> que devuelve un boleano si la palabra forma parte o no de la lista de las stop worlds. Por tanto, creo una lista vacía y a partir de la iteración de tokens en doc verifico el resultado de cada atributo y si es verdadero los agrego a la lista. Para eliminarlos he creado un nuevo objeto donde solo agrego aquellos tokens que den falso."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"font-size: 14pt; font-weight: bold; color: #0098cd;\">Pregunta 6.</span>\n",
    "<span style=\"font-size: 14pt; font-weight: bold; color: #0098cd;\">¿Qué atributo del token contiene la etiqueta NER?</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-27T21:41:54.719079Z",
     "start_time": "2023-04-27T21:41:54.715533Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token: Chicago - NER: GPE\n",
      "Token: America - NER: GPE\n",
      "Token: tonight - NER: TIME\n",
      "Token: three - NER: TIME\n",
      "Token: hours - NER: TIME\n",
      "Token: four - NER: TIME\n",
      "Token: hours - NER: TIME\n",
      "Token: first - NER: ORDINAL\n",
      "Token: Democrat - NER: NORP\n",
      "Token: Republican - NER: NORP\n",
      "Token: Hispanic - NER: NORP\n",
      "Token: Asian - NER: NORP\n",
      "Token: Native - NER: NORP\n",
      "Token: American - NER: NORP\n",
      "Token: Americans - NER: NORP\n",
      "Token: the - NER: GPE\n",
      "Token: United - NER: GPE\n",
      "Token: States - NER: GPE\n",
      "Token: of - NER: GPE\n",
      "Token: America - NER: GPE\n",
      "Token: tonight - NER: TIME\n",
      "Token: America - NER: GPE\n",
      "Token: Washington - NER: GPE\n",
      "Token: Des - NER: GPE\n",
      "Token: Moines - NER: GPE\n",
      "Token: Concord - NER: GPE\n",
      "Token: Charleston - NER: GPE\n",
      "Token: $ - NER: MONEY\n",
      "Token: 5 - NER: MONEY\n",
      "Token: and - NER: MONEY\n",
      "Token: $ - NER: MONEY\n",
      "Token: 10 - NER: MONEY\n",
      "Token: and - NER: MONEY\n",
      "Token: $ - NER: MONEY\n",
      "Token: 20 - NER: MONEY\n",
      "Token: millions - NER: CARDINAL\n",
      "Token: Americans - NER: NORP\n",
      "Token: more - NER: DATE\n",
      "Token: than - NER: DATE\n",
      "Token: two - NER: DATE\n",
      "Token: centuries - NER: DATE\n",
      "Token: later - NER: DATE\n",
      "Token: Earth - NER: LOC\n",
      "Token: tonight - NER: TIME\n",
      "Token: tomorrow - NER: DATE\n",
      "Token: two - NER: CARDINAL\n",
      "Token: a - NER: DATE\n",
      "Token: century - NER: DATE\n",
      "Token: tonight - NER: TIME\n",
      "Token: Americans - NER: NORP\n",
      "Token: Iraq - NER: GPE\n",
      "Token: Afghanistan - NER: GPE\n",
      "Token: one - NER: DATE\n",
      "Token: year - NER: DATE\n",
      "Token: one - NER: CARDINAL\n",
      "Token: America - NER: GPE\n",
      "Token: tonight - NER: TIME\n",
      "Token: America - NER: GPE\n",
      "Token: 221 - NER: DATE\n",
      "Token: years - NER: DATE\n",
      "Token: 21 - NER: DATE\n",
      "Token: months - NER: DATE\n",
      "Token: ago - NER: DATE\n",
      "Token: winter - NER: DATE\n",
      "Token: this - NER: TIME\n",
      "Token: autumn - NER: TIME\n",
      "Token: night - NER: TIME\n",
      "Token: Main - NER: FAC\n",
      "Token: Street - NER: FAC\n",
      "Token: one - NER: CARDINAL\n",
      "Token: one - NER: CARDINAL\n",
      "Token: first - NER: ORDINAL\n",
      "Token: the - NER: ORG\n",
      "Token: Republican - NER: ORG\n",
      "Token: Party - NER: ORG\n",
      "Token: the - NER: ORG\n",
      "Token: White - NER: ORG\n",
      "Token: House - NER: ORG\n",
      "Token: the - NER: ORG\n",
      "Token: Democratic - NER: ORG\n",
      "Token: Party - NER: ORG\n",
      "Token: tonight - NER: TIME\n",
      "Token: Lincoln - NER: ORG\n",
      "Token: Americans - NER: NORP\n",
      "Token: tonight - NER: TIME\n",
      "Token: tonight - NER: TIME\n",
      "Token: American - NER: NORP\n",
      "Token: America - NER: GPE\n",
      "Token: Tonight - NER: TIME\n",
      "Token: America - NER: GPE\n",
      "Token: America - NER: GPE\n",
      "Token: tomorrow - NER: DATE\n",
      "Token: tonight - NER: TIME\n",
      "Token: Atlanta - NER: GPE\n",
      "Token: millions - NER: CARDINAL\n",
      "Token: one - NER: CARDINAL\n",
      "Token: Ann - NER: PERSON\n",
      "Token: Nixon - NER: PERSON\n",
      "Token: Cooper - NER: PERSON\n",
      "Token: 106 - NER: DATE\n",
      "Token: years - NER: DATE\n",
      "Token: old - NER: DATE\n",
      "Token: two - NER: CARDINAL\n",
      "Token: tonight - NER: TIME\n",
      "Token: America - NER: GPE\n",
      "Token: American - NER: NORP\n",
      "Token: Montgomery - NER: ORG\n",
      "Token: Birmingham - NER: GPE\n",
      "Token: Selma - NER: GPE\n",
      "Token: Atlanta - NER: GPE\n",
      "Token: the - NER: LOC\n",
      "Token: moon - NER: LOC\n",
      "Token: Berlin - NER: GPE\n",
      "Token: this - NER: DATE\n",
      "Token: year - NER: DATE\n",
      "Token: 106 - NER: DATE\n",
      "Token: years - NER: DATE\n",
      "Token: America - NER: GPE\n",
      "Token: hours - NER: TIME\n",
      "Token: America - NER: GPE\n",
      "Token: America - NER: GPE\n",
      "Token: tonight - NER: TIME\n",
      "Token: the - NER: DATE\n",
      "Token: next - NER: DATE\n",
      "Token: century - NER: DATE\n",
      "Token: Ann - NER: PERSON\n",
      "Token: Nixon - NER: PERSON\n",
      "Token: Cooper - NER: PERSON\n",
      "Token: American - NER: NORP\n"
     ]
    }
   ],
   "source": [
    "tokens_ner = filter(lambda token: token.ent_type_, doc)\n",
    "for token in tokens_ner:\n",
    "    print(\"Token: {} - NER: {}\".format(token.text, token.ent_type_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Incluye aquí, debajo de la línea, la explicación de tu respuesta</b>\n",
    "<hr>\n",
    "Como solo queremos los atributos que contengan una etiqueta, voy a filtrar aquellos tokens que formen parte de una entidad reconocida para no quedarnos con aquellos que puedan contener una cadena vacía. Para ello, <i>ent_type</i> nos devuelve el nombre de la etiqueta NER del token. Luego itero por el filtro creado para imprimir el texto contenido en el token y su etiqueta NER asociada.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"font-size: 14pt; font-weight: bold; color: #0098cd;\">Pregunta 7.</span>\n",
    "<span style=\"font-size: 14pt; font-weight: bold; color: #0098cd;\">¿Qué entidades soporta Spacy?, ¿Qué significa cada una?</span>\n",
    "\n",
    "<b>Nota</b>: Debes escribir el código que liste las entidades disponibles y la explicación de las mismas. El listado sin código se considerará respuesta incompleta."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-27T21:41:54.724441Z",
     "start_time": "2023-04-27T21:41:54.721094Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['tok2vec', 'tagger', 'parser', 'attribute_ruler', 'lemmatizer', 'ner']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nlp.pipe_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-27T21:41:54.727950Z",
     "start_time": "2023-04-27T21:41:54.725448Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('CARDINAL', 'DATE', 'EVENT', 'FAC', 'GPE', 'LANGUAGE', 'LAW', 'LOC', 'MONEY', 'NORP', 'ORDINAL', 'ORG', 'PERCENT', 'PERSON', 'PRODUCT', 'QUANTITY', 'TIME', 'WORK_OF_ART')\n"
     ]
    }
   ],
   "source": [
    "labels = nlp.get_pipe(\"ner\").labels\n",
    "print(labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Incluye aquí, debajo de la línea, la explicación de tu respuesta</b>\n",
    "<hr>\n",
    "Al cargar el modelo de lenguaje, podemos generar un Pipeline para obtener todas sus entidades soportadas. Como solo nos interesa comprobar las etiquetas NER, primero he impreso el nombre de las pipelines disponibles para luego poder filtrar por esa en concreto con la función <i>get_pipe()</i> y listar las opciones con <i>labels</i>.\n",
    "\n",
    "Una breve explicación del significado de cada una:\n",
    "\n",
    "- CARDINAL: Números cardinales .\n",
    "- DATE: Fechas absolutas o relativas .\n",
    "- EVENT: Eventos (festivales, conciertos, competiciones deportivas, etc.) \n",
    "- FAC: Edificios, aeropuertos, carreteras, puentes, etc. \n",
    "- GPE: Ubicaciones geopolíticas (países, ciudades o estados)\n",
    "- LANGUAGE: Idiomas.\n",
    "- LAW: Documentos legales (leyes, resoluciones, etc.) \n",
    "- LOC: Localizaciones concretas no geo-políticas (montañas, ríos, mares, etc.)\n",
    "- MONEY: Referencias a dinero, monedas y valores.\n",
    "- NORP: Nacionalidades y religiones.\n",
    "- ORDINAL: Números ordinales. \n",
    "- ORG: Organizaciones o empresas (compañías, agencias gubernamentales, partidos políticos, etc.)\n",
    "- PERCENT: Porcentajes.\n",
    "- PERSON: Nombres de personas. \n",
    "- PRODUCT: Objetos y productos comerciales. \n",
    "- QUANTITY: Medidas y cantidades.\n",
    "- TIME: Tiempos.\n",
    "- WORK_OF_ART: Obras artísticas (libros, pinturas, canciones, etc.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"font-size: 14pt; font-weight: bold; color: #0098cd;\">Pregunta 8.</span>\n",
    "<span style=\"font-size: 14pt; font-weight: bold; color: #0098cd;\">¿Qué entidades diferentes son reconocidas en el texto?, ¿cuántas hay de cada tipo?</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-27T21:41:54.732507Z",
     "start_time": "2023-04-27T21:41:54.728964Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPE: 24\n",
      "TIME: 16\n",
      "ORDINAL: 2\n",
      "NORP: 12\n",
      "MONEY: 1\n",
      "CARDINAL: 8\n",
      "DATE: 12\n",
      "LOC: 2\n",
      "FAC: 1\n",
      "ORG: 5\n",
      "PERSON: 2\n"
     ]
    }
   ],
   "source": [
    "num_ner = {}\n",
    "\n",
    "labels = [ent.label_ for ent in doc.ents]\n",
    "for label in labels:\n",
    "    if label in num_ner:\n",
    "        num_ner[label] += 1\n",
    "    else:\n",
    "        num_ner[label] = 1\n",
    "\n",
    "for ent, count in num_ner.items():\n",
    "    print(f\"{ent}: {count}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Incluye aquí, debajo de la línea, la explicación de tu respuesta</b>\n",
    "<hr>\n",
    "Para hacer el recuento de los diferentes NER, he creado una lista vacía con la que a partir de un sumador he incremetado su valor según la ocurrencia de cada etiqueta cada vez que aparecía en el doc. He conseguido hacer el recuento gracias a que <i>doc.ents</i> contiene todas las entidades nombradas encontradas en el texto. He guardado esta lista en <i>labels</i>, que luego he recorrido guardando en cada clave (que corresponde con la entidad) el nuevo valor de apariciones. Por último, recorro la lista resultante imprimiendo cada etiqueta con la suma de su frencuencia. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"font-size: 14pt; font-weight: bold; color: #0098cd;\">Pregunta 9.</span>\n",
    "<span style=\"font-size: 14pt; font-weight: bold; color: #0098cd;\">Explica con tus palabras qué es el código IOB para el reconocimiento de entiedades. Pon un ejemplo, sacado del texto, de una etiqueta de un único token y una etiqueta compuesta por varios tokens.</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-27T21:41:54.736586Z",
     "start_time": "2023-04-27T21:41:54.733519Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPE: Chicago\n"
     ]
    }
   ],
   "source": [
    "# Etiqueta compuesta por un único token\n",
    "for token in doc:\n",
    "    if token.ent_type_ and len(token.text.split()) == 1:\n",
    "        print(f\"{token.ent_type_}: {token.text}\")\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-27T21:41:54.740422Z",
     "start_time": "2023-04-27T21:41:54.737596Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TIME: three hours\n"
     ]
    }
   ],
   "source": [
    "# Etiqueta compuesta por varios tokens\n",
    "for ent in doc.ents:\n",
    "    if len(ent.text.split()) > 1:\n",
    "        print(f\"{ent.label_}: {ent.text}\")\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Incluye aquí, debajo de la línea, la explicación de tu respuesta</b>\n",
    "<hr>\n",
    "El código IOB (Inside, Outside, Beginning) es un formato de etiquetado para transformar tokens a chunks utilzado en el named-entity recognition. Las etiquetas son parecidas al POS tagging, pero indican el \"interior\", \"exterior\" y \"principio\" de un chunk. Cada token se etiqueta con una de las tres etiquetas IOB: \"I\" si es un token adicional que forma parte de la entidad, \"O\" si el token no forma parte de ninguna y \"B\" si es el primer token de una entidad.\n",
    "\n",
    "Para obtener una etiqueta con un único token, parto del nombre de la entidad del token y que la longitud de su texto no sea mayor de 1, imprimo la primera ocurrencia que se ha encontrado en el doc añadiendo un break. Si quiero buscar varios tokens formando una etiqueta compuesta, entonces voy a partir de la entidad en vez del token y la división del texto que contiene debe ser mayor de 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
